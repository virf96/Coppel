{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "pipeline de datos para entrenamiento - version 3 .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/virf96/Coppel/blob/main/pipeline_de_datos_para_entrenamiento_version_3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "fb60c11cad1d4ff480398356a4fc964f"
      },
      "source": [
        "# Pipeline de datos\n",
        "Este notebook contiene todas las funciones necesarias para crear un dataset de training y evaluacion de nuestro modelo de churn.\n",
        "\n",
        "Esta dividido en tres partes, seteo de parametros, obtencion de datos, y contstruccion del dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db9cb074633246f8974814c686999acd"
      },
      "source": [
        "## Obtencion de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a01d0f93ad44e1797a026ec578fe837"
      },
      "source": [
        "TABLA_VENTAS: str = \"MUESTRA_TRANSACCIONES_VENTAS\"\n",
        "TABLA_HIST_CORTE: str = \"MUESTRA_HISTORIAL_CORTE\"\n",
        "TABLA_DESERCION: str = \"MUESTRA_DATADESERCION\"\n",
        "TABLA_SOCIODEMOGRAFICA: str = \"MUESTRA_SOCIODEMOGRAFICA\"\n",
        "TABLA_DEVOLUCIONES: str = \"DEVOLUCIONES\"\n",
        "FECHA_PRIMER_DIA: str = \"2020-07-01\"\n",
        "VARIABLES_OBJETIVO=True\n",
        "buffer=2\n",
        "meses_pre=12\n",
        "meses_post=12\n",
        "submuestra = None\n",
        "fechas_festivas = {\n",
        "    \"navidad\": \"2019-12-25\",\n",
        "    \"dia_madres\": \"2019-05-10\",\n",
        "    \"regreso_clases\": \"2019-08-20\",\n",
        "    \"semana_santa\": \"2020-04-12\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80808f0b7dc74d338f84fd050ebd2394"
      },
      "source": [
        "import calendar\n",
        "import datetime\n",
        "import jaydebeapi\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "from project_lib import Project"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5e5789428964eb29220b30338d8ef34"
      },
      "source": [
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "\n",
        "# Credenciales del proyecto\n",
        "project = Project.access()\n",
        "NZSQL_DIRECCIONRIESGOS_credentials = project.get_connection(\n",
        "    name=\"NZSQL_DIRECCIONRIESGOS\"\n",
        ")\n",
        "\n",
        "# Conexión a la base de datos\n",
        "url_con = \"{}://{}:{}/{}\".format(\n",
        "    \"jdbc:netezza\",\n",
        "    NZSQL_DIRECCIONRIESGOS_credentials[\"host\"],\n",
        "    NZSQL_DIRECCIONRIESGOS_credentials[\"port\"],\n",
        "    NZSQL_DIRECCIONRIESGOS_credentials[\"database\"],\n",
        ")\n",
        "\n",
        "# Establecer conexión a la base de datos desde pandas\n",
        "NZSQL_DIRECCIONRIESGOS_connection = jaydebeapi.connect(\n",
        "    'org.netezza.Driver',\n",
        "    url_con,\n",
        "    [NZSQL_DIRECCIONRIESGOS_credentials['username'],\n",
        "    NZSQL_DIRECCIONRIESGOS_credentials['password']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d258a7dc14fe42db8e49e1795126dfcd"
      },
      "source": [
        "def get_restriccion(\n",
        "    tabla: str = \"MUESTRA_TRANSACCIONES_VENTA\",\n",
        "    campo_fecha: str = \"FECHACOMPRA\",\n",
        "    fecha_min: str = \"\",\n",
        "    fecha_max: str = \"\",\n",
        "    submuestra: int = None,\n",
        "    campo_cliente: str = \"IDCTE\",\n",
        "):\n",
        "    \"\"\"Obtener una muestra de la tabla.\n",
        "    Se pueden poner restricciones vinculadas al campo fecha, o al campo cliente.\n",
        "\n",
        "    \"\"\"\n",
        "    if tabla != \"MUESTRA_SOCIODEMOGRAFICA\":\n",
        "        if submuestra is None:\n",
        "            muestra = f\"\"\"({campo_fecha} >= '{fecha_min}' AND {campo_fecha} < '{fecha_max}')\"\"\"\n",
        "        else:\n",
        "            muestra = f\"\"\"({campo_fecha} >= '{fecha_min}'AND {campo_fecha} < '{fecha_max}'AND {campo_cliente} LIKE '%{submuestra}5')\"\"\"\n",
        "    else:\n",
        "        if submuestra is None:\n",
        "            muestra = None\n",
        "        else:\n",
        "            muestra = f\"\"\"({campo_cliente} LIKE '%{submuestra}5') \"\"\"\n",
        "    return muestra"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0fb26841c4943ac8023238cbd9a0ec2"
      },
      "source": [
        "### Procesamiento transacciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0da731a5877c4f65b17d5c0145d395c3"
      },
      "source": [
        "def get_monto_compra_numero_productos_mes(\n",
        "    restriccion: str,\n",
        "    tabla: str = TABLA_VENTAS,\n",
        "    NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "):\n",
        "    consulta = f\"\"\"\n",
        "    WITH venta_dia AS (\n",
        "        SELECT CLIENTECODIGO,\n",
        "            FECHACOMPRA,\n",
        "            SUM(PRECIO_VTA) AS precio_venta_factura,\n",
        "            COUNT(CODIGO) AS items_venta_factura\n",
        "        FROM {tabla}\n",
        "        WHERE {restriccion}\n",
        "        GROUP BY CLIENTECODIGO, FECHACOMPRA\n",
        "        )\n",
        "    SELECT CLIENTECODIGO,\n",
        "        DATE_PART('MONTH',FECHACOMPRA) AS MES,\n",
        "        DATE_PART('YEAR',FECHACOMPRA) AS ANIO,\n",
        "        COUNT(DISTINCT(FECHACOMPRA)) AS numero_compras,\n",
        "        SUM(precio_venta_factura) AS monto_compra_total,\n",
        "        AVG(precio_venta_factura) AS monto_compra_promedio,\n",
        "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY precio_venta_factura) AS monto_compra_mediana,\n",
        "        MAX(precio_venta_factura) AS monto_compra_maximo,\n",
        "        MIN(precio_venta_factura) AS monto_compra_minimo,\n",
        "        SUM(items_venta_factura) AS items_compra_total,\n",
        "        AVG(items_venta_factura) AS items_compra_promedio,\n",
        "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY items_venta_factura) AS items_compra_mediana,\n",
        "        MAX(items_venta_factura) AS items_compra_maximo,\n",
        "        MIN(items_venta_factura) AS items_compra_minimo\n",
        "        FROM venta_dia\n",
        "        GROUP BY CLIENTECODIGO, MES, ANIO\n",
        "        ORDER BY ANIO, MES, CLIENTECODIGO\n",
        "    \"\"\"\n",
        "    df = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "    df = df.rename(columns = str.lower).rename(columns = {'clientecodigo':'CLIENTECODIGO', 'mes':'MES', 'anio':'ANIO'})\n",
        "    return df\n",
        "\n",
        "\n",
        "def agregar_mes_relativo(\n",
        "    df, fecha_de_corte, columna_anio=\"ANIO\", columna_mes=\"MES\"\n",
        "):\n",
        "    df[\"mes_relativo\"] = np.round(\n",
        "        (\n",
        "            pd.to_datetime(\n",
        "                [\n",
        "                    \"{}-{}-01\".format(y, m)\n",
        "                    for y, m in zip(df[columna_anio], df[columna_mes])\n",
        "                ]\n",
        "            )\n",
        "            - pd.to_datetime(fecha_de_corte)\n",
        "        ).days\n",
        "        / 30,\n",
        "        0,\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "def generar_datos_meses_anteriores(df, indice=\"CLIENTECODIGO\"):\n",
        "    # Funcion para generar un dataset con una fila por cliente, con los datos\n",
        "    # agregados de cada mes, con fecha de corte establecida en fecha_de_corte\n",
        "\n",
        "    df = (\n",
        "        df.drop(columns=[\"MES\", \"ANIO\"])\n",
        "        .pivot(index=indice, columns=\"mes_relativo\")\n",
        "        .reset_index()\n",
        "    )\n",
        "    df.columns = [\"\".join([col[0], str(col[1])]) for col in df.columns]\n",
        "    return df\n",
        "\n",
        "\n",
        "def generar_variables_objetivo(df, indice=\"CLIENTECODIGO\"):\n",
        "    # Funcion que devuelve un dataframe con las cuatro variables objetivo calculadas\n",
        "\n",
        "    # Variables a calcular. Key es el nombre, value es una tupla con el rango de meses a calcular, no inclusive\n",
        "    periodos = {\n",
        "        \"compra_1\": (0, 2),\n",
        "        \"compra_3\": (0, 4),\n",
        "        \"compra_6\": (0, 7),\n",
        "        \"compra_12\": (0, 13),\n",
        "    }\n",
        "\n",
        "    dfs = []\n",
        "    for periodo in periodos:\n",
        "        periodo_df = (\n",
        "            df[\n",
        "                (df[\"mes_relativo\"] > periodos[periodo][0])\n",
        "                & (df[\"mes_relativo\"] < periodos[periodo][1])\n",
        "            ][[indice, \"numero_compras\"]]\n",
        "            .groupby(indice)[\"numero_compras\"]\n",
        "            .sum()\n",
        "            > 0\n",
        "        ).to_frame(name=periodo)\n",
        "        dfs.append(periodo_df)\n",
        "\n",
        "    return pd.concat(dfs, axis=1).reset_index().fillna(False)\n",
        "\n",
        "\n",
        "def generar_estadisticas_compras(df, indice=\"CLIENTECODIGO\"):\n",
        "    variables = [\"numero_compras\", \"monto_compra_total\", \"items_compra_total\"]\n",
        "    df_pasado = df[(df[\"mes_relativo\"] < -1)]\n",
        "\n",
        "    dfs = []\n",
        "    for variable in variables:\n",
        "\n",
        "        group = df_pasado[[indice, variable]].groupby(indice)[variable]\n",
        "        dfs.append(group.mean().to_frame(f\"promedio_{variable}\"))\n",
        "        dfs.append(group.median().to_frame(f\"mediana_{variable}\"))\n",
        "        dfs.append(group.max().to_frame(f\"max_{variable}\"))\n",
        "\n",
        "    return pd.concat(dfs, axis=1).reset_index()\n",
        "\n",
        "\n",
        "def preparar_df_ventas(\n",
        "    df,\n",
        "    fecha_de_corte,\n",
        "    columna_anio=\"ANIO\",\n",
        "    columna_mes=\"MES\",\n",
        "    indice=\"CLIENTECODIGO\",\n",
        "    variables_objetivo=False,\n",
        "):\n",
        "    # A partir de una tabla de ventas por mes y cliente, genera un dataframe con un cliente por row,\n",
        "    # con sus datos agregados para cada mes, y la variable objetivo\n",
        "\n",
        "    # Agrego el mes relativo a la fecha de corte\n",
        "    df = agregar_mes_relativo(df, fecha_de_corte = fecha_de_corte, columna_anio = columna_anio, columna_mes = columna_mes )\n",
        "\n",
        "    if variables_objetivo:\n",
        "        # Creo un dataframe con las variables objetivo a 1, 3, 6 y 12 meses\n",
        "        df_variables_objetivo = generar_variables_objetivo(df, indice)\n",
        "\n",
        "    # Genero el promedio/max/mediana de la cantidad de items/cantidad de compras/monto total por mes\n",
        "    estadisticas_compras_agregadas = generar_estadisticas_compras(df, indice)\n",
        "\n",
        "    # Con las variables objetivo construidas, elimino todas las filas de despues de la fecha de corte\n",
        "    # Elimino el mes inmediatamente anterior a la fecha de corte por el delay de datos en produccion\n",
        "    df = df[df[\"mes_relativo\"] < -1]\n",
        "\n",
        "    # Agrego los datos de los meses anteriores\n",
        "    df = generar_datos_meses_anteriores(df)\n",
        "\n",
        "    if variables_objetivo:\n",
        "        # Finalmente, mergeo los dataframes para crear el conjunto de datos completo\n",
        "        df_final_ventas = pd.merge(df, df_variables_objetivo, on=indice, how=\"left\")\n",
        "        df_final_ventas[\n",
        "            [\"compra_1\", \"compra_3\", \"compra_6\", \"compra_12\"]\n",
        "        ] = df_final_ventas[[\"compra_1\", \"compra_3\", \"compra_6\", \"compra_12\"]].fillna(\n",
        "            value=False\n",
        "        )\n",
        "    else:\n",
        "        df_final_ventas = df\n",
        "\n",
        "    return df_final_ventas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98b8ec46426640138ad30f3e27428168"
      },
      "source": [
        "## Fechas relevantes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2hwFgrINyA2"
      },
      "source": [
        "def ventas_dia(restriccion_historica_compra, tabla: str = TABLA_VENTAS):\n",
        "    consulta = f\"\"\"\n",
        "    SELECT CLIENTECODIGO,\n",
        "        FECHACOMPRA,\n",
        "        SUM(PRECIO_VTA) AS precio_venta_factura,\n",
        "        COUNT(CODIGO) AS items_venta_factura\n",
        "        FROM {tabla}\n",
        "        WHERE {restriccion_historica_compra}\n",
        "        GROUP BY CLIENTECODIGO, FECHACOMPRA\n",
        "    \"\"\"\n",
        "    return pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "\n",
        "\n",
        "def ponderar_variable_distancia_fecha(\n",
        "    df, fecha, output_col_name, variable=\"items_venta_factura\", k=0.8\n",
        "):\n",
        "    df = df.groupby([\"CLIENTECODIGO\", \"FECHACOMPRA\"])[variable].sum().reset_index()\n",
        "    df[\"FECHACOMPRA\"] = pd.to_datetime(df[\"FECHACOMPRA\"])\n",
        "    df[\"datediff\"] = pd.to_datetime(fecha) - df[\"FECHACOMPRA\"]\n",
        "    df.loc[df.datediff < pd.to_timedelta(1, \"d\"), \"datediff\"] = pd.to_timedelta(-1, \"d\")\n",
        "    df[\"weight\"] = 1 / df.datediff.dt.days ** k\n",
        "    df[output_col_name] = df.weight * df[variable]\n",
        "    condition = df.datediff > pd.to_timedelta(0, \"d\")\n",
        "    df[output_col_name].where(condition, 0, inplace=True)\n",
        "    \n",
        "    return df.set_index(\"CLIENTECODIGO\").loc[:, output_col_name]\n",
        "\n",
        "\n",
        "def get_variables_fechas_relevantes(fechas, restriccion_historica_compra, indice=\"CLIENTECODIGO\", tabla=TABLA_VENTAS):\n",
        "    df_dia = ventas_dia(tabla=TABLA_VENTAS, restriccion_historica_compra = restriccion_historica_compra)\n",
        "    variable = \"ITEMS_VENTA_FACTURA\"\n",
        "    df_dia_fechas = []\n",
        "    for nombre_fecha, fecha in fechas.items():\n",
        "        df_dia_fechas.append(\n",
        "            ponderar_variable_distancia_fecha(df_dia, fecha, nombre_fecha, variable)\n",
        "        )\n",
        "\n",
        "    df_clientes = (\n",
        "        pd.concat(df_dia_fechas, axis=1).groupby(indice)[list(fechas.keys())].sum()\n",
        "    )\n",
        "    return df_clientes.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b1f17937b32402d96cecf262e8c4e68"
      },
      "source": [
        "### Canal compras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "941fb92bdd4148b0a0d04730f585cc6d"
      },
      "source": [
        "def get_cliente_canal_venta_prop(\n",
        "    restriccion: str,\n",
        "    tabla: str = TABLA_VENTAS,\n",
        "    NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "):\n",
        "    # Canales por cliente\n",
        "    condicion_canal = f\"\"\"\n",
        "    CASE WHEN SUM(DISTINCT(FLAG_FISICO)) = 1 AND SUM(DISTINCT(FLAG_DIGITAL)) = 0 THEN 'FISICO' \n",
        "         WHEN SUM(DISTINCT(FLAG_FISICO)) = 0 AND SUM(DISTINCT(FLAG_DIGITAL)) = 1 THEN 'DIGITAL'\n",
        "         WHEN SUM(DISTINCT(FLAG_FISICO)) = 1 AND SUM(DISTINCT(FLAG_DIGITAL)) = 1 THEN 'AMBOS'\n",
        "         ELSE 'NA' END\n",
        "    \"\"\"\n",
        "    condicion_frecuencia_canal = f\"\"\"\n",
        "    CASE WHEN SUM(DISTINCT(FLAG_FISICO)) = 1 AND SUM(DISTINCT(FLAG_DIGITAL)) = 0 THEN 1\n",
        "         WHEN SUM(DISTINCT(FLAG_FISICO)) = 0 AND SUM(DISTINCT(FLAG_DIGITAL)) = 1 THEN 0\n",
        "         WHEN SUM(DISTINCT(FLAG_FISICO)) = 1 AND SUM(DISTINCT(FLAG_DIGITAL)) = 1 THEN (SUM(FLAG_FISICO) / (SUM(FLAG_FISICO) + SUM(FLAG_DIGITAL)))\n",
        "         ELSE NULL END\n",
        "    \"\"\"\n",
        "    consulta = f\"\"\"\n",
        "    WITH compra_dia AS (\n",
        "        SELECT \n",
        "            CLIENTECODIGO,\n",
        "            FECHACOMPRA,\n",
        "            SUM(DISTINCT(FLAG_FISICO)) AS FLAG_FISICO,\n",
        "            SUM(DISTINCT(FLAG_DIGITAL)) AS FLAG_DIGITAL\n",
        "        FROM {tabla} \n",
        "        WHERE {restriccion}\n",
        "        GROUP BY CLIENTECODIGO, FECHACOMPRA)\n",
        "    SELECT \n",
        "        CLIENTECODIGO,\n",
        "        {condicion_canal} AS CANAL,\n",
        "        {condicion_frecuencia_canal} AS PROP_CANAL_FISICO\n",
        "    FROM compra_dia\n",
        "    GROUP BY CLIENTECODIGO\n",
        "    \"\"\"\n",
        "    df = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "    df[\"PROP_CANAL_FISICO\"] = round(df[\"PROP_CANAL_FISICO\"], 2)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "604125fa559f4eaa8788a03ae5839bfa"
      },
      "source": [
        "### Social demografico"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a6c1107ce81436a8308266fa8882c2e"
      },
      "source": [
        "def get_sociodemografico(\n",
        "    fecha_de_corte,\n",
        "    tabla: str = TABLA_SOCIODEMOGRAFICA,\n",
        "    NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "    restriccion: str = None\n",
        "):\n",
        "    if restriccion:\n",
        "        consulta = f\"\"\"\n",
        "        SELECT \n",
        "            NUMCLIENTE,\n",
        "            FECHANACIMIENTO,\n",
        "            GENERO,\n",
        "            ESTADOCIVIL,\n",
        "            ESCOLARIDADCODIGO,\n",
        "            NUMDEDEPENDIENTES,\n",
        "            ESTADOCODIGO,\n",
        "            TIPOVIVIENDA,\n",
        "            MONTOINGRESOMENSUAL,\n",
        "            TAMCIUDAD,\n",
        "            TIEMPOTRABAJO,\n",
        "            TIEMPOVIVIENDA,\n",
        "            NUMEROHIJOS,\n",
        "            FLAGTELEFONOVC,\n",
        "            FLAGTELEFONOCELULARVC,\n",
        "            FLAGCORREOELECTRONICOVC,\n",
        "            FECHAALTA \n",
        "        FROM {tabla}\n",
        "        WHERE {restriccion}\n",
        "        \"\"\"\n",
        "    else:\n",
        "        consulta = f\"\"\"\n",
        "        SELECT \n",
        "            NUMCLIENTE,\n",
        "            FECHANACIMIENTO,\n",
        "            GENERO,\n",
        "            ESTADOCIVIL,\n",
        "            ESCOLARIDADCODIGO,\n",
        "            NUMDEDEPENDIENTES,\n",
        "            ESTADOCODIGO,\n",
        "            TIPOVIVIENDA,\n",
        "            MONTOINGRESOMENSUAL,\n",
        "            TAMCIUDAD,\n",
        "            TIEMPOTRABAJO,\n",
        "            TIEMPOVIVIENDA,\n",
        "            NUMEROHIJOS,\n",
        "            FLAGTELEFONOVC,\n",
        "            FLAGTELEFONOCELULARVC,\n",
        "            FLAGCORREOELECTRONICOVC,\n",
        "            FECHAALTA \n",
        "        FROM {tabla}\n",
        "        \"\"\"\n",
        "    df = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "    \n",
        "    df = df.rename(columns={\"NUMCLIENTE\": \"CLIENTECODIGO\"})\n",
        "    \n",
        "    # Calcular antiguedades\n",
        "    df[\"edad\"] = (\n",
        "        pd.to_datetime(fecha_de_corte) - pd.to_datetime(df[\"FECHANACIMIENTO\"])\n",
        "    ).dt.days / 365\n",
        "    df[\"edad\"] = df[\"edad\"].fillna(0).astype(\"int\")\n",
        "    df[\"dias_de_antiguedad\"] = (\n",
        "        pd.to_datetime(fecha_de_corte) - pd.to_datetime(df[\"FECHAALTA\"])\n",
        "    ).dt.days\n",
        "    df[\"dias_de_tiempotrabajo\"] = (\n",
        "        pd.to_datetime(fecha_de_corte) - pd.to_datetime(df[\"TIEMPOTRABAJO\"])\n",
        "    ).dt.days\n",
        "    df[\"dias_de_tiempovivienda\"] = (\n",
        "        pd.to_datetime(fecha_de_corte) - pd.to_datetime(df[\"TIEMPOVIVIENDA\"])\n",
        "    ).dt.days\n",
        "\n",
        "    df.drop(\n",
        "        [\"FECHAALTA\", \"TIEMPOTRABAJO\", \"TIEMPOVIVIENDA\", \"FECHANACIMIENTO\"],\n",
        "        axis=1,\n",
        "        inplace=True,\n",
        "    )\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd2c573b21294968806373866c7c318d"
      },
      "source": [
        "### Categorias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "234a91ea647746d2b1c44c91ffde8d14"
      },
      "source": [
        "def get_categorias(\n",
        "    restriccion: str,\n",
        "    tabla: str = TABLA_VENTAS,\n",
        "    NZSQL_DIRECCIONRIESGOS_connection= NZSQL_DIRECCIONRIESGOS_connection,\n",
        "):\n",
        "    # Se excluyen las compras que tienen departamento 'Sin Descripcion'.\n",
        "    # Se Obtienen las categorias mas frecuentes para cada cliente\n",
        "\n",
        "    consulta = f\"\"\"WITH ListaCategorias AS\n",
        "     (SELECT CLIENTECODIGO, DESDEPARTAMENTO, COUNT(*) AS CuentaCategoria, SUM(PRECIO_VTA) AS MontoCategoria\n",
        "        FROM {tabla}\n",
        "        WHERE {restriccion} AND DESDEPARTAMENTO != 'Sin Descripcion'\n",
        "        GROUP BY CLIENTECODIGO, DESDEPARTAMENTO\n",
        "        )\n",
        "        SELECT s.CLIENTECODIGO, s.DESDEPARTAMENTO AS departamento_mas_frecuente, s.MontoCategoria, m.num_departamentos\n",
        "            FROM ListaCategorias AS s\n",
        "            JOIN (SELECT s.CLIENTECODIGO, MAX(s.CuentaCategoria) AS MaxCategoria, COUNT(DISTINCT DESDEPARTAMENTO) AS num_departamentos\n",
        "                FROM ListaCategorias AS s\n",
        "                WHERE DESDEPARTAMENTO != 'Sin Descripcion'\n",
        "                GROUP BY s.CLIENTECODIGO\n",
        "                ) AS m\n",
        "        ON s.CLIENTECODIGO = m.CLIENTECODIGO AND s.CuentaCategoria = m.MaxCategoria\"\"\"\n",
        "    df = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "    \n",
        "    df = df.rename(\n",
        "        columns={\n",
        "            \"DEPARTAMENTO_MAS_FRECUENTE\": \"departamento_mas_frecuente\",\n",
        "            \"NUM_DEPARTAMENTOS\":\"num_departamentos\",\n",
        "            \"MONTOCATEGORIA\":\"MontoCategoria\"\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    #Si hay empate elegir el de mayor monto\n",
        "    max_montos = df.groupby(['CLIENTECODIGO']).MontoCategoria.transform(max)\n",
        "    df = df.loc[df.MontoCategoria == max_montos]\n",
        "    \n",
        "    #Si hay empate nuevamente elegir de forma aleatoria\n",
        "    df = df.drop_duplicates(subset = 'CLIENTECODIGO')\n",
        "    \n",
        "    # Eliminar la columna MontoCategoria\n",
        "    df = df.drop(columns = 'MontoCategoria')\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60fc51870caf470e8152abae9a163078"
      },
      "source": [
        "## Saldos, vencidos, abonos, intereses, recargos, linea credito real, puntualidad -X meses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a514fd66707342fd8eede0d2239f750e"
      },
      "source": [
        "def preparar_df_por_cliente(\n",
        "    df,\n",
        "    fecha_de_corte,\n",
        "    columna_anio=\"ANIO\",\n",
        "    columna_mes=\"MES\",\n",
        "    indice=\"CLIENTECODIGO\",\n",
        "):\n",
        "    # A partir de una tabla de ventas por mes y cliente, genera un dataframe con un cliente por row, con sus datos agregados para cada mes, y la variable objetivo\n",
        "\n",
        "    # Agrego el mes relativo a la fecha de corte\n",
        "    df = agregar_mes_relativo(df, fecha_de_corte)\n",
        "\n",
        "    # Con las variables objetivo construidas, elimino todas las filas de despues de la fecha de corte\n",
        "    # Elimino el mes inmediatamente anterior a la fecha de corte por el delay de datos en produccion\n",
        "    df = df[df[\"mes_relativo\"] < -1]\n",
        "\n",
        "    # Agrego los datos de los meses anteriores\n",
        "    df = generar_datos_meses_anteriores(df, indice=indice)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_saldos_mes(\n",
        "    restriccion: str,\n",
        "    tabla: str = TABLA_DESERCION,\n",
        "    NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "):\n",
        "    consulta = f\"\"\"\n",
        "    SELECT IDCTE,\n",
        "        DATE_PART('MONTH',FECHACORTE) AS MES,\n",
        "        DATE_PART('YEAR',FECHACORTE) AS ANIO,\n",
        "        SUM(SDOACT) AS SALDOACTUAL, SUM(SDOVDO) AS SALDOVDO, SUM(INTNORMAL) AS INTERESNORMAL, SUM(INTMOR) AS INTERESMOR, SUM(LINEA_CRED_REAL) AS CREDITO, PUNTUALIDAD\n",
        "        FROM {tabla} WHERE {restriccion}\n",
        "        GROUP BY IDCTE, MES, ANIO, PUNTUALIDAD\n",
        "        ORDER BY ANIO, MES, IDCTE\n",
        "    \"\"\"\n",
        "    df = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "    df = df.rename(\n",
        "        columns={\n",
        "            \"IDCTE\": \"CLIENTECODIGO\",\n",
        "            \"SALDOACTUAL\": \"total_SDOACT\",\n",
        "            \"SALDOVDO\": \"total_SDOVDO\",\n",
        "            \"INTERESNORMAL\": \"total_INTNORMAL\",\n",
        "            \"INTERESMOR\": \"total_INTMOR\",\n",
        "            \"CREDITO\": \"total_LINEA_CRED_REAL\",\n",
        "            \"first(PUNTUALIDAD)\": \"PUNTUALIDAD\",\n",
        "        }\n",
        "    )\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e79e4e8c7da446e9aff3774280d1c24b"
      },
      "source": [
        "### Devoluciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b6d4e3d777b4297aeb2c4fea7068795"
      },
      "source": [
        "def get_devoluciones(\n",
        "    restriccion: str,\n",
        "    tabla: str = TABLA_DEVOLUCIONES,\n",
        "    NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "):\n",
        "    consulta = (\n",
        "        f\"SELECT NUMCLIENTE FROM {TABLA_DEVOLUCIONES} WHERE {restriccion} GROUP BY NUMCLIENTE\"\n",
        "    )\n",
        "    devoluciones = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "\n",
        "    devoluciones[\"devoluciones\"] = True\n",
        "    devoluciones = devoluciones.rename(columns={\"NUMCLIENTE\": \"CLIENTECODIGO\"})\n",
        "\n",
        "    return devoluciones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9c2d08009d3433e8056ce003c7150e6"
      },
      "source": [
        "### Dias ultima compra"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efd8b1812ee0430ca41796740451e1e9"
      },
      "source": [
        "# No implementado aun\n",
        "\n",
        "def get_dias_ultima_compra(\n",
        "    tabla: str = TABLA_HIST_CORTE\n",
        "    FECHA_PRIMER_DIA: str = FECHA_PRIMER_DIA\n",
        "    FECHA_CORTE: str = FECHA_CORTE\n",
        "    buffer=2,\n",
        "    campo_fecha: str = \"FECHACORTE\",\n",
        "    NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "    \n",
        "):\n",
        "    fecha_min = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=-(buffer + 1))\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "    fecha_max = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=-(buffer))\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "    restriccion_fecha = (\n",
        "        f\"{campo_fecha} >= '{fecha_min}' AND {campo_fecha} < '{fecha_max}'\"\n",
        "    )    \n",
        "    \n",
        "    \n",
        "    consulta = f\"SELECT CLIENTECODIGO, F_ULT_COMP_T FROM {tabla} WHERE {restriccion_fecha}\"\n",
        "    print(consulta)\n",
        "    \n",
        "    df = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "    df[\"dias_desde_ultima_compra\"] = (\n",
        "        pd.to_datetime(FECHA_CORTE) - pd.to_datetime(df[\"F_ULT_COMP_T\"])\n",
        "    ).dt.days\n",
        "    df = df.drop(columns=[\"F_ULT_COMP_T\"])\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4dece6696f44e0793667fd57fba640b"
      },
      "source": [
        "# Dataset final"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a08897f02d1a403f8451c5b9dfbf657b"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef34bd97c24247a1b666c4e3af1d5d3b"
      },
      "source": [
        "def generar_dataset(\n",
        "    TABLA_VENTAS: str = \"MUESTRA_TRANSACCIONES_VENTAS\",\n",
        "    TABLA_HIST_CORTE: str = \"MUESTRA_HISTORIAL_CORTE\",\n",
        "    TABLA_DESERCION: str = \"MUESTRA_DATADESERCION\",\n",
        "    TABLA_SOCIODEMOGRAFICA: str = \"MUESTRA_SOCIODEMOGRAFICA\",\n",
        "    TABLA_DEVOLUCIONES: str = \"DEVOLUCIONES\",\n",
        "    FECHA_PRIMER_DIA: str = \"2020-07-01\",\n",
        "    VARIABLES_OBJETIVO=True,\n",
        "    buffer=2,\n",
        "    meses_pre=12,\n",
        "    meses_post=12,\n",
        "    submuestra = None,\n",
        "    fechas_festivas = {\n",
        "    \"navidad\": \"2019-12-25\",\n",
        "    \"dia_madres\": \"2019-05-10\",\n",
        "    \"regreso_clases\": \"2019-08-20\",\n",
        "    \"semana_santa\": \"2020-04-12\",\n",
        "}\n",
        "):\n",
        "    \"\"\"\n",
        "    FECHA_PRIMER_DIA: Fecha del primer dia que se quiere predecir\n",
        "    \"\"\"\n",
        "    t1 = time.time()\n",
        "\n",
        "    #print('STARTING')\n",
        "    #Fechas\n",
        "    FECHA_CORTE = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=-1)\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "    FECHA_HIST_MIN = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=-(buffer + meses_pre))\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "    FECHA_HIST_MAX = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=-(buffer))\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "    MAX_FECHA_VAR_OBJETIVO = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=+(meses_post))\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    #Restricciones\n",
        "    restriccion_historica_tabla_ventas = get_restriccion(\n",
        "        tabla = TABLA_VENTAS, fecha_min=FECHA_HIST_MIN, fecha_max=FECHA_HIST_MAX, submuestra = submuestra, campo_cliente = 'CLIENTECODIGO'\n",
        "    )\n",
        "    \n",
        "    restriccion_sociodemografica = get_restriccion(tabla = TABLA_SOCIODEMOGRAFICA, submuestra = submuestra, campo_cliente = 'NUMCLIENTE')\n",
        "    \n",
        "    \n",
        "    restriccion_historica_desercion = get_restriccion(\n",
        "        tabla = TABLA_DESERCION, fecha_min=FECHA_HIST_MIN, fecha_max=FECHA_HIST_MAX, campo_fecha = 'FECHACORTE', submuestra = submuestra, campo_cliente = 'IDCTE'\n",
        "    )\n",
        "    \n",
        "    restriccion_historica_devolucion = get_restriccion(\n",
        "        tabla = TABLA_DEVOLUCIONES, fecha_min=FECHA_HIST_MIN, fecha_max=FECHA_HIST_MAX, campo_fecha = 'FECHACORTE', submuestra = submuestra, campo_cliente = 'NUMCLIENTE'\n",
        "    )\n",
        "\n",
        "    # Transacciones Ventas\n",
        "    if VARIABLES_OBJETIVO:\n",
        "        restriccion_tiempo_total = get_restriccion(\n",
        "        fecha_min=FECHA_HIST_MIN, fecha_max=MAX_FECHA_VAR_OBJETIVO, submuestra= submuestra, campo_cliente = 'CLIENTECODIGO'\n",
        "        )\n",
        "        \n",
        "        print(\"Generando monto de compras\", time.time()-t1)\n",
        "        df_vars_montos_compras = get_monto_compra_numero_productos_mes(\n",
        "            tabla=TABLA_VENTAS, restriccion=restriccion_tiempo_total\n",
        "        )\n",
        "        \n",
        "\n",
        "        print(\"Generando agregaciones por mes de compras\",time.time()-t1)\n",
        "        df_final_ventas = preparar_df_ventas(\n",
        "            df=df_vars_montos_compras, variables_objetivo=VARIABLES_OBJETIVO, fecha_de_corte = FECHA_CORTE\n",
        "        )\n",
        "\n",
        "\n",
        "    else:\n",
        "        restriccion_historica_compra = get_restriccion(\n",
        "        fecha_min=FECHA_HIST_MIN, fecha_max=FECHA_HIST_MAX, submuestra = submuestra, campo_cliente = 'CLIENTECODIGO'\n",
        "        )\n",
        "        \n",
        "        print(\"Generando monto de compras\", time.time()-t1)\n",
        "        df_vars_montos_compras = get_monto_compra_numero_productos_mes(\n",
        "            tabla=TABLA_VENTAS, restriccion=restriccion_historica_compra\n",
        "        )\n",
        "\n",
        "        print(\"Generando agregaciones por mes de compras\", time.time()-t1)\n",
        "        df_final_ventas = preparar_df_ventas(\n",
        "            df=df_vars_montos_compras, variables_objetivo=VARIABLES_OBJETIVO, fecha_de_corte = FECHA_CORTE\n",
        "        )\n",
        "\n",
        "    # Canal cliente\n",
        "    print(\"Generando canales por cliente\", time.time()-t1)\n",
        "    df_canal_cliente_prop = get_cliente_canal_venta_prop(\n",
        "        tabla=TABLA_VENTAS, restriccion=restriccion_historica_tabla_ventas\n",
        "    )\n",
        "\n",
        "    # Social demografico    \n",
        "    print(\"Generando datos social demograficos\",time.time()-t1)\n",
        "    df_socioeconomico = get_sociodemografico(tabla = TABLA_SOCIODEMOGRAFICA, fecha_de_corte=FECHA_CORTE, restriccion = restriccion_sociodemografica)\n",
        "\n",
        "    # Categorias\n",
        "    print(\"Generando datos de categorias\",time.time()-t1)\n",
        "    df_categorias = get_categorias(\n",
        "        tabla=TABLA_VENTAS, restriccion=restriccion_historica_tabla_ventas\n",
        "    )\n",
        "\n",
        "    # Saldos\n",
        "    print(\"Generando datos de saldos\", time.time()-t1)\n",
        "    df_vars_desercion = get_saldos_mes(\n",
        "        tabla=TABLA_DESERCION, restriccion=restriccion_historica_desercion\n",
        "    )\n",
        "    df_vars_desercion_cliente = preparar_df_por_cliente(\n",
        "        df_vars_desercion, fecha_de_corte=FECHA_CORTE\n",
        "    )\n",
        "\n",
        "    # Devoluciones\n",
        "    print(\"Generando dataset devoluciones\", time.time()-t1)\n",
        "    devoluciones_df = get_devoluciones(\n",
        "        tabla=TABLA_DEVOLUCIONES, restriccion=restriccion_historica_devolucion\n",
        "    )\n",
        "    \n",
        "    \n",
        "    # Fechas feriados\n",
        "    print(\"Generando dataset fechas\", time.time()-t1)\n",
        "    df_fechas_festivas = get_variables_fechas_relevantes(fechas = fechas_festivas, restriccion_historica_compra = restriccion_historica_tabla_ventas)\n",
        "    \n",
        "    \n",
        "    # Dataset obtenido al hacer join en todos los df\n",
        "    print(\"Generando dataset final\",time.time()-t1)\n",
        "    df_final = pd.merge(\n",
        "        df_final_ventas, df_canal_cliente_prop, how=\"inner\", on=\"CLIENTECODIGO\"\n",
        "    )\n",
        "    df_final = pd.merge(df_final, df_socioeconomico, how=\"inner\", on=\"CLIENTECODIGO\")\n",
        "    df_final = pd.merge(df_final, df_categorias, how=\"left\", on=\"CLIENTECODIGO\")\n",
        "    df_final = pd.merge(\n",
        "        df_final, df_vars_desercion_cliente, how=\"left\", on=\"CLIENTECODIGO\"\n",
        "    )\n",
        "    df_final = pd.merge(df_final, devoluciones_df, how=\"left\", on=\"CLIENTECODIGO\")\n",
        "    df_final[\"devoluciones\"] = df_final[\"devoluciones\"].fillna(False)\n",
        "    df_final = pd.merge(df_final, df_fechas_festivas, how = \"left\", on = \"CLIENTECODIGO\")\n",
        "    \n",
        "    return df_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e157cc7baf9948b88d8f6248fa4426a9"
      },
      "source": [
        "def aplicar_filtro(\n",
        "    df_final,\n",
        "    TABLA_DESERCION: str = \"MUESTRA_DATADESERCION\",\n",
        "    lista_estatus: str = \"'Activos Sin Vencido', 'Vencidos 1', 'Nunca 0-15', 'Saldados 0-15'\",\n",
        "    FECHA_PRIMER_DIA: str = \"2020-07-01\",\n",
        "    buffer=2,\n",
        "    campo_fecha: str = \"FECHACORTE\",\n",
        "    NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "    \n",
        "):\n",
        "    \"\"\" Funcion para filtrar los clientes de acuerdo a lo propuesto para el sprint 3\n",
        "    \"\"\"\n",
        "\n",
        "    fecha_min = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=-(buffer + 1))\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "    fecha_max = (\n",
        "        pd.to_datetime(FECHA_PRIMER_DIA) + relativedelta(months=-(buffer))\n",
        "    ).strftime(\"%Y-%m-%d\")\n",
        "    restriccion_fecha = (\n",
        "        f\"{campo_fecha} >= '{fecha_min}' AND {campo_fecha} < '{fecha_max}'\"\n",
        "    )\n",
        "\n",
        "    consulta = f\"\"\"SELECT IDCTE,  ESTATUSMIGRACION\n",
        "            FROM {TABLA_DESERCION}\n",
        "            WHERE {restriccion_fecha} \n",
        "            AND ESTATUSMIGRACION IN ({lista_estatus}) \n",
        "            GROUP BY IDCTE, ESTATUSMIGRACION\"\"\"\n",
        "    df = pd.read_sql(consulta, con=NZSQL_DIRECCIONRIESGOS_connection)\n",
        "    df = df.rename(columns = {'IDCTE':'CLIENTECODIGO'})\n",
        "    \n",
        "    df_entrenamiento_filtro = pd.merge(df_final, df, how = 'inner')\n",
        "    df_entrenamiento_filtro = df_entrenamiento_filtro.drop(columns = 'ESTATUSMIGRACION')\n",
        "    return df_entrenamiento_filtro"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "840d36a4cdfa44ebb36a8a7ccaaff081"
      },
      "source": [
        "months = pd.date_range(\"2019-07\", \"2020-07\", freq ='MS' )\n",
        "fechas_festivas = {\n",
        "    \"navidad\": [\"2018-12-25\", \"2019-12-25\", \"2020-12-25\"],\n",
        "    \"dia_madres\": [\"2018-05-10\",\"2019-05-10\",\"2020-05-10\"],\n",
        "    \"regreso_clases\": [\"2018-08-20\",\"2019-08-26\",\"2020-08-30\"],\n",
        "    \"semana_santa\": [\"2018-04-01\", \"2019-04-21\", \"2020-04-12\"],\n",
        "}\n",
        "df_fechas_festivas = pd.DataFrame.from_dict(fechas_festivas).astype('datetime64[ns]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3505c38a00a4425a8cacabef5a246f1"
      },
      "source": [
        "def get_fechas_festivas(df_fechas_festivas, fecha_primer_dia, buffer =2, meses_pre = 12):\n",
        "    condicion = (df_fechas_festivas < m) & (df_fechas_festivas > m - relativedelta(months=(buffer + meses_pre)))\n",
        "    return df_fechas_festivas[condicion].melt() \\\n",
        "                                        .dropna() \\\n",
        "                                        .set_index('variable').astype(str) \\\n",
        "                                        .value.to_dict()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2db88c3a31742628773a40cf88c6da5",
        "outputId": "68fe2e36-ba26-42f4-d840-6a4c8017f8d3"
      },
      "source": [
        "print('STARTING')\n",
        "t1 = time.time()\n",
        "\n",
        "df = []\n",
        "for m  in months:\n",
        "    \n",
        "    print(\"Processing\", m, time.time()-t1)\n",
        "    \n",
        "    ff = get_fechas_festivas(df_fechas_festivas, m)\n",
        "    print(ff)\n",
        "    df_month =  generar_dataset(\n",
        "        TABLA_VENTAS = \"MUESTRA_TRANSACCIONES_VENTAS\",\n",
        "        TABLA_HIST_CORTE = \"MUESTRA_HISTORIAL_CORTE\",\n",
        "        TABLA_DESERCION = \"MUESTRA_DATADESERCION\",\n",
        "        TABLA_SOCIODEMOGRAFICA = \"MUESTRA_SOCIODEMOGRAFICA\",\n",
        "        TABLA_DEVOLUCIONES = \"DEVOLUCIONES\",\n",
        "        FECHA_PRIMER_DIA = m,\n",
        "        VARIABLES_OBJETIVO=True,\n",
        "        buffer=2,\n",
        "        meses_pre=12,\n",
        "        meses_post=12,\n",
        "        submuestra = 2,\n",
        "        fechas_festivas = ff\n",
        "    )\n",
        "    print('Filtrando churners involuntarios')\n",
        "    df_month = aplicar_filtro(\n",
        "        df_month,\n",
        "        TABLA_DESERCION = \"MUESTRA_DATADESERCION\",\n",
        "        lista_estatus = \"'Activos Sin Vencido', 'Vencidos 1', 'Nunca 0-15', 'Saldados 0-15'\",\n",
        "        FECHA_PRIMER_DIA = m,\n",
        "        buffer=2,\n",
        "        campo_fecha = \"FECHACORTE\",\n",
        "        NZSQL_DIRECCIONRIESGOS_connection=NZSQL_DIRECCIONRIESGOS_connection,\n",
        "    )\n",
        "    df.append(df_month)\n",
        "    \n",
        "print('concatenando meses...')\n",
        "df = pd.concat(df)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "STARTING\nProcessing 2019-07-01 00:00:00 0.0004792213439941406\n{'navidad': '2018-12-25', 'dia_madres': '2019-05-10', 'regreso_clases': '2018-08-20', 'semana_santa': '2019-04-21'}\nGenerando monto de compras 0.0003829002380371094\nGenerando agregaciones por mes de compras 296.2789969444275\nGenerando canales por cliente 298.282812833786\nGenerando datos social demograficos 307.87141013145447\nGenerando datos de categorias 520.8761978149414\nGenerando datos de saldos 533.2948966026306\nGenerando dataset devoluciones 810.1661105155945\nGenerando dataset fechas 810.8061430454254\nGenerando dataset final 849.9321048259735\nDONE! Duracion: 851.1893074512482\nFiltrando churners involuntarios\nProcessing 2019-08-01 00:00:00 934.3486957550049\n{'navidad': '2018-12-25', 'dia_madres': '2019-05-10', 'regreso_clases': '2018-08-20', 'semana_santa': '2019-04-21'}\nGenerando monto de compras 0.0002739429473876953\nGenerando agregaciones por mes de compras 313.12663531303406\nGenerando canales por cliente 315.42642521858215\nGenerando datos social demograficos 324.51542258262634\nGenerando datos de categorias 543.591582775116\nGenerando datos de saldos 557.7383666038513\nGenerando dataset devoluciones 897.3046255111694\nGenerando dataset fechas 897.7792949676514\nGenerando dataset final 946.3283710479736\nDONE! Duracion: 948.1431291103363\nFiltrando churners involuntarios\nProcessing 2019-09-01 00:00:00 1968.4519441127777\n{'navidad': '2018-12-25', 'dia_madres': '2019-05-10', 'regreso_clases': '2019-08-26', 'semana_santa': '2019-04-21'}\nGenerando monto de compras 0.00024962425231933594\n",
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-042c1facdee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmeses_post\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msubmuestra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mfechas_festivas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Filtrando churners involuntarios'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-3ecda9bd17f7>\u001b[0m in \u001b[0;36mgenerar_dataset\u001b[0;34m(TABLA_VENTAS, TABLA_HIST_CORTE, TABLA_DESERCION, TABLA_SOCIODEMOGRAFICA, TABLA_DEVOLUCIONES, FECHA_PRIMER_DIA, VARIABLES_OBJETIVO, buffer, meses_pre, meses_post, submuestra, fechas_festivas)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generando monto de compras\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         df_vars_montos_compras = get_monto_compra_numero_productos_mes(\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mtabla\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTABLA_VENTAS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriccion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestriccion_tiempo_total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         )\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-f37a14290d0c>\u001b[0m in \u001b[0;36mget_monto_compra_numero_productos_mes\u001b[0;34m(restriccion, tabla, NZSQL_DIRECCIONRIESGOS_connection)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mORDER\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mANIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIENTECODIGO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsulta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNZSQL_DIRECCIONRIESGOS_connection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'clientecodigo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'CLIENTECODIGO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mes'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'MES'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'anio'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'ANIO'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/Python-3.7-OpenCE/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         )\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/Python-3.7-OpenCE/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1644\u001b[0m             )\n\u001b[1;32m   1645\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetchall_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/Python-3.7-OpenCE/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36m_fetchall_as_list\u001b[0;34m(self, cur)\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fetchall_as_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/Python-3.7-OpenCE/lib/python3.7/site-packages/jaydebeapi/__init__.py\u001b[0m in \u001b[0;36mfetchall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/envs/Python-3.7-OpenCE/lib/python3.7/site-packages/jaydebeapi/__init__.py\u001b[0m in \u001b[0;36mfetchone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetColumnCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0msqltype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetColumnType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_converters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqltype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_unknownSqlTypeConverter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f74b8a985af446586fa537ae7f4522f",
        "scrolled": true
      },
      "source": [
        "from project_lib import Project\n",
        "project = Project.access()\n",
        "print('guardando dataset...')\n",
        "project.save_data(file_name = \"df_entrenamiento_filtro_25_rolling_window.csv\",data = df.to_csv(index=False))\n",
        "print(\"DONE!\", 'Duracion:',time.time()-t1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}